{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 40.220 The Analytics Edge Mid Term Revision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R version 3.5.0 (2018-04-23)\n",
       "Platform: x86_64-apple-darwin15.6.0 (64-bit)\n",
       "Running under: macOS High Sierra 10.13.5\n",
       "\n",
       "Matrix products: default\n",
       "BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib\n",
       "LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib\n",
       "\n",
       "locale:\n",
       "[1] C/UTF-8/C/C/C/C\n",
       "\n",
       "attached base packages:\n",
       "[1] stats     graphics  grDevices utils     datasets  methods   base     \n",
       "\n",
       "other attached packages:\n",
       "[1] glmnet_2.0-16  foreach_1.4.4  Matrix_1.2-14  caTools_1.17.1\n",
       "\n",
       "loaded via a namespace (and not attached):\n",
       " [1] Rcpp_0.12.17         codetools_0.2-15     lattice_0.20-35     \n",
       " [4] digest_0.6.16        crayon_1.3.4         bitops_1.0-6        \n",
       " [7] IRdisplay_0.5.0      grid_3.5.0           repr_0.15.0         \n",
       "[10] jsonlite_1.5         magrittr_1.5         evaluate_0.11       \n",
       "[13] stringi_1.2.2        uuid_0.1-2           IRkernel_0.8.12.9000\n",
       "[16] iterators_1.0.9      tools_3.5.0          stringr_1.3.1       \n",
       "[19] compiler_3.5.0       base64enc_0.1-3      htmltools_0.3.6     \n",
       "[22] pbdZMQ_0.3-3        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sessionInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a document containing a list of functions that would be useful for your mid term/finals. If necessary, to illustrate an example, the data will be loaded from a particular dataset. Ensure that the dataset is stored in a directory called 'Dataset'. \n",
    "\n",
    "Datasets used:\n",
    "* wine.csv\n",
    "* Orings.csv\n",
    "* Hitters.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we jump in..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset wine.csv to illustrate some examples because it is simple to understand and play around with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wine<-read.csv(\"Dataset/wine.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str(wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary(wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. General functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix generation \n",
    "Array must be listed column down first, then row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m <- matrix(c(3,4,5,6,7,8), nrow=3, ncol=2)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array generation\n",
    "Note: the difference between array and matrix is that matrix is max 2-dim but array can be > 2-dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n <- array(c(3,4,5,6,7,8), c(3,2,1)) \n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe generation\n",
    "Creates a dataframe where columns can be viewed as attributes and rows viewed as observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t <- data.frame(names=c(\"karthik\",\"sam\",\"jim\"),\n",
    "                ages = c(36,34,40),\n",
    "                sex = c(\"M\",\"F\",\"M\"),\n",
    "                children=c(2,0,1))\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call t$names to list out all the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t$names\n",
    "names(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting a particular column and table generation\n",
    "Tabulate and sum up over the chosen attribute. Especially useful for COUNTING number of observations in an attribute (e.g. how many times is the temperature between 14-15 degree celcius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rounded down to create a few categories\n",
    "\n",
    "table(floor(wine$DEGREES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can further create a dataframe from a table, which might be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DegreesDF<-as.data.frame(table(wine$DEGREES_ROUNDED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the size/dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim(wine) # applies for dataframe/matrix\n",
    "length(wine$VINT) # applies for a particular column/array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining new columns in a dataframe\n",
    "You can create a new column in a dataframe by simply naming a new variable on the left of '<-' and writing the expression on the right of '<-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wine$LPRICEx2 <- wine$LPRICE * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with missing entries\n",
    "We can find missing entries in LPRICE by returning a boolean array that checks if there is a missing entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is.na(wine$LPRICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remove the whole observation/row in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wine_narm<-wine[!is.na(wine$LPRICE),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method works as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wine_narm2<-na.omit(wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removes missing entries when applying mean() function. na.rm argument exists for some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean(wine$LPRICE) \n",
    "mean(wine$LPRICE, na.rm=TRUE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing specific rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can use the splicing operator [] to choose specific rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using row index\n",
    "wine[2,] # to choose row 2\n",
    "wine[-2,] # to choose every row except row 2\n",
    "# using a condition\n",
    "wine[wine$DEGREES>16,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the subset() function to choose specific rows"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "subset(wine, wine$DEGREES>16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing specific columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the splicing operator [] to choose specific columns as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wine[,c(\"WRAIN\", \"DEGREES\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the subset() function to choose specific columns\n",
    "\n",
    "Note: subset() function is used to segregate data based on certain condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subset(wine, select=c(WRAIN, DEGREES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use subset() function to remove unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subset(wine, select=-c(WRAIN,DEGREES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### which() function\n",
    "which() function returns an index or array of indexes, for which the condition is TRUE. Note: in comparison to which.max() which only returns ONE index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x<-c(1,2,3,6,3,6)\n",
    "which(x==max(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful for checking indexes that have missing entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "which(is.na(wine$LPRICE))\n",
    "wine[which(is.na(wine$LPRICE)),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful for finding indexes of highest/lowest values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max(wine$HRAIN)\n",
    "which(wine$HRAIN==max(wine$HRAIN)) # alternatively, look at which.max()\n",
    "wine[17,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### which.___ function\n",
    "which.max() function returns the index of the maximum value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "which.max(wine$HRAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casting to a new type\n",
    "We can cast a variable to the desired type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "as.logical(1)\n",
    "as.numeric(TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is especially important when the data is a factor and you need to change it into numeric type. If you convert it into numeric directly from factor, R will convert it into integers based on the level of the factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wrain_factor<-as.factor(wine$WRAIN)\n",
    "#wrain_factor\n",
    "\n",
    "# Wrong\n",
    "as.numeric(wrain_factor)\n",
    "\n",
    "# Correct\n",
    "as.numeric(as.character(wrain_factor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Family of apply functions\n",
    "TAPPLY()\n",
    ">R documentation: Apply a function to each cell of a ragged array, that is to each (non-empty) group of values given by a unique combination of the levels of certain factors.\n",
    "\n",
    "Idea: Given tapply(arg1, arg2, func), we are applying the function over arg1 grouped according to arg2. (If you know Python Pandas, this is similar to GroupBy)\n",
    "\n",
    "In the following example, we can find the mean LPRICE based on the each category of DEGREES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove na data for tapply\n",
    "wine_tapply<-na.omit(wine)\n",
    "# floor it to create a few categories\n",
    "tapply(wine_tapply$LPRICE, floor(wine_tapply$DEGREES), mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create a table to tabulate the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table(tapply(wine_tapply$LPRICE, floor(wine_tapply$DEGREES), mean))\n",
    "# not meaningful due to the data.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAPPLY()/SAPPLY()\n",
    ">R documentation: lapply returns a list of the same length as X, each element of which is the result of applying FUN to the corresponding element of X. sapply is a user-friendly version and wrapper of lapply by default returning a vector, matrix or, if simplify = \"array\", an array if appropriate, by applying simplify2array(). sapply(x, f, simplify = FALSE, USE.NAMES = FALSE) is the same as lapply(x, f).\n",
    "\n",
    "Idea: Given sapply(arg1, func), we are applying the function over each element in arg1\n",
    "\n",
    "In the following example, we can create a function to add 1 and apply it on an array\n",
    "\n",
    "Note: sapply returns a vector or a matrix while lapply returns a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "addOne<-function(x){\n",
    "    return (x+1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myarray<-c(1,2,3)\n",
    "sapply(myarray, addOne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APPLY()\n",
    ">Returns a vector or array or list of values obtained by applying a function to margins of an array or matrix.\n",
    "\n",
    "Idea: Given apply(arg1, margin, func), we are applying the function across the row if margin==1 and across column if margin==2. This is a neat function if you want to find out the average values across observation of a column for a dataset. \n",
    "\n",
    "In the following example, we can determine the average WRAIN and DEGREES in the wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#?apply\n",
    "#apply(wine[,c('WRAIN')],2,mean) # x must be an array\n",
    "apply(wine[,c('WRAIN','DEGREES')],2,mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data between train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(caTools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1: using sample.split() with a balanced ratio of dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove na data\n",
    "wine_narm<-na.omit(wine)\n",
    "# create categories for LPRICE\n",
    "wine_narm$LPRICE_CAT <- wine_narm$LPRICE>-1.0\n",
    "table(wine_narm$LPRICE_CAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spl <- sample.split(wine_narm, 0.75)\n",
    "train <- subset(wine_narm, spl==TRUE)\n",
    "test <- subset(wine_narm, spl==FALSE)\n",
    "table(train$LPRICE_CAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table(test$LPRICE_CAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metod 2: using sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainID<-sample(1:nrow(wine_narm),nrow(wine_narm)/2) # sample(start_index:end_index, number_of_rows_to_split)\n",
    "train<-wine_narm[trainID,]\n",
    "test<-wine_narm[-trainID,]\n",
    "str(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical t-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performs a statistical one sample t-test to test the hypothesis if mean value=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t.test(wine$DEGREES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performs a statistical two sample t-test to test if the sample mean of the two samples are sufficiently different. In this case, we are determining whether the sample mean of DEGREES of VINT < 1973 and sample mean of DEGREES of VINT >= 1973 is significantly different. Clearly, the null hypothesis should not be rejected, which means that the sample means are not significantly different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t.test(subset(wine,wine$VINT<1973)$DEGREES, subset(wine,wine$VINT>=1973)$DEGREES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other (potentially) useful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Finding min/max in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min(wine$DEGREES)\n",
    "max(wine$DEGREES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sorting values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wine$WRAIN\n",
    "sort(wine$WRAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Correlation and removing NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cor(wine$WRAIN, wine$LPRICE, use=\"pairwise.complete.obs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* State a specific ordering for factors, instead of based on alphabetical order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df <- data.frame(days=c(\"monday\",\"tuesday\",\"wednesday\",\"friday\",\"monday\"),\n",
    "                customers = c(36,34,40,100,2))\n",
    "str(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tapply(df$customers, df$days, sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df$days<-factor(df$days, ordered=TRUE, levels=c(\"monday\", \"tuesday\", \"wednesday\", \"thursday\", \"friday\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tapply(df$customers, df$days, sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* List attributes of objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names(wine)\n",
    "wine$LPRICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Graph Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset in-built faithful from R for graph plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data(faithful)\n",
    "str(faithful)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting a scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot(faithful)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drawing lines between the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot(faithful, type=\"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting of Histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X axis starts from 1.6 and ends at 5.2 with 0.2 breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist(faithful$eruptions, breaks=seq(1.6,5.2,0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting of the empirical culmulative distribution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot.ecdf(faithful$eruptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting of Q-Q plot to generate the normal quantile plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qqnorm(faithful$eruptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(caTools)\n",
    "set.seed(1)\n",
    "spl<-sample.split(wine, SplitRatio = 0.75)\n",
    "train<-subset(wine, spl==TRUE)\n",
    "test<-subset(wine, spl==FALSE)\n",
    "str(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a linear regression model with LPRICE as the output and the other variables (i.e. VINT, WRAIN, DEGREES, HRAIN, TIME-SV) as predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm_model <- lm(LPRICE~., data=train)\n",
    "summary(lm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear regression formula**: \n",
    "\n",
    "\\begin{equation*}\n",
    "predicted\\ LRPICE = 38.9 - 0.0253VINT +0.000603WRAIN + 0.578DEGREES - 0.00396HRAIN \n",
    "\\end{equation*}\n",
    "\n",
    "Notes on summary of linear regression model:\n",
    "\n",
    "Predictor-specific\n",
    "* **Estimate**: the beta values in the linear model\n",
    "* **Std. Error**: varability in the beta value\n",
    "* **t value**: the variable used for hypothesis testing for each predictor. The higher the absolute of t value, the smaller the p value, hence the more significant the variable \n",
    "* **Pr(>|t|)**: the p value of the hypothesis testing for each predictor. Hypothesis test will test whether the null hypothesis (beta=0) should be rejected. If the p value is small (typically $<$0.05), we can reject the null hypothesis that beta=0 and claim that beta is significant in explaining the model\n",
    "\n",
    "Overall model\n",
    "\n",
    "(note: n=number of observations, p=number of predictor variables)\n",
    "* **Residual standard error**: is a measure of the lack of fit of the model. The smaller the RSE, the better\n",
    "\n",
    "\\begin{equation*}\n",
    "RSE = \\sqrt{\\frac{SSE}{n-p-1}}\n",
    "\\end{equation*}\n",
    "\n",
    "* **Multiple R-squared**: normal R<sup>2</sup>\n",
    "* **Adjusted R-squared**: takes into consideration of the complexity of the model (i.e. number of predictors in the model)\n",
    "\n",
    "\\begin{equation*}\n",
    "Adjusted\\ R^2 = 1 - (1-R^2)(\\frac{n-1}{n-p-1})\n",
    "\\end{equation*}\n",
    "\n",
    "* **F-statistic**: the variable used for hypothesis testing for the whole model\n",
    "* **p-value**: the p value of hypothesis testing for the whole model. A low p-value means that the overall model is significant in explaining the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other kinds of ways to use lm() for linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm_model2 <- lm(LPRICE~VINT+WRAIN, data=train) # train with VINT and WRAIN as predictor\n",
    "lm_model3 <- lm(LPRICE~.-VINT, data=train) # remove one predictor using '-' before the predictor\n",
    "lm_model4 <- lm(LPRICE~.-1, data=train) # remove the intercept using '-1' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions using the linear regression model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict(lm_model, newdata=test)\n",
    "# ignore the warning message. it is due to empty beta coefficient for TIME_SV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it is a single-variable model, we can plot the datapoints and the best fit graph from the model to see how well the model fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm_model5 <- lm(LPRICE~DEGREES, data=train)\n",
    "plot(train$DEGREES, train$LPRICE)\n",
    "abline(lm_model5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum of squared errors (SSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SSE represents the variation not accounted for by the model. Remember this: (true - predicted)\n",
    "\n",
    "\\begin{equation*}\n",
    "SSE = \\sum_{i=1}^n (true - predicted)^2\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Method 1 (only on train data since it can only be obtained from the model)\n",
    "sse<-sum(lm_model$residuals^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Method 2 (for both train and test data)\n",
    "sse<-sum((train$LPRICE-predict(lm_model, newdata=train))^2, na.rm = TRUE)\n",
    "sse\n",
    "# again, ignore the warning message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that here we are finding the SSE of the train dataset. We can find the SSE of the test dataset as well by switching the arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum of total squared (SST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SST represents the total variation in the dataset. Remember this: (true - mean)\n",
    "\n",
    "\\begin{equation*}\n",
    "SSE = \\sum_{i=1}^n (true - mean)^2\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sst<-sum((train$LPRICE-mean(train$LPRICE, na.rm=TRUE))^2, na.rm = TRUE)\n",
    "sst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: when evaluating SST on the test data, we use the mean of the train data, instead of the test data. This is because the model is meant to fit the train dataset, hence the beta0, the intercept of the model is the mean of the train dataset. If we were to use the mean of the test dataset and the mean of the test dataset varies greatly from the train dataset, the model would perform poorly on the r<sup>2</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R<sup>2</sup> \n",
    "\n",
    "R<sup>2</sup> represents the amount of variation in the dataset that is accounted for by the model. Essentially, it is a measure of model fit to the data. Hence, the formula:\n",
    "\n",
    "\\begin{equation*}\n",
    "R^2 = \\frac{SST-SSE}{SST} = 1-\\frac{SSE}{SST}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1-sse/sst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In simple linear regression, (cor(output,predictor))<sup>2</sup> = r<sup>2</sup>. Proof is in the notes. You can verify this using R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We use a different dataset for logistic regression: orings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orings<-read.csv(\"Dataset/Orings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str(orings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary(orings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glm_model<-glm(Field~Temp+Pres,data=orings,family=binomial)\n",
    "summary(glm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic regression formula**: \n",
    "\\begin{equation*}\n",
    "P(Field=1) = \\frac{e^{3.96 - 0.119Temp + 0.00869Pres}}{1+e^{3.96 - 0.119Temp + 0.00869Pres}}\\\\\n",
    "P(Field=0) = 1-P(Field=1)\n",
    "\\end{equation*}\n",
    "\n",
    "Notes on summary of logistic regression model:\n",
    "\n",
    "Predictor-specific\n",
    "* **Estimate**: the beta values in the logistic model\n",
    "* **Std. Error**: varability in the beta value\n",
    "* **z value**: the variable used for hypothesis testing for each predictor. The higher the absolute of z value, the smaller the p value, hence the more significant the variable \n",
    "* **Pr(>|z|)**: the p value of the hypothesis testing for each predictor. Hypothesis test will test whether the null hypothesis (beta=0) should be rejected. If the p value is small (typically $<$0.05), we can reject the null hypothesis that beta=0 and claim that beta is significant in explaining the model\n",
    "\n",
    "Overall model\n",
    "* **Null deviance**: refers to how well the model fits if given the intercept as the only predictor\n",
    "\n",
    "\\begin{equation*}\n",
    "Null\\ deviance = - 2 LL(only\\ intercept)\n",
    "\\end{equation*}\n",
    "\n",
    "* **Residual deviance**: refers to how well the model fits if given the other predictors as well. A significant decrease from null to residual deviance indicates that the predictors are useful\n",
    "\n",
    "\\begin{equation*}\n",
    "Residual\\ deviance = - 2 LL(\\hat \\beta)\n",
    "\\end{equation*}\n",
    "\n",
    "* **AIC**: refers to deviance but penalises model complexity\n",
    "    * accounts for both i) fit to data and ii) model complexity (similar to adjusted R<sup>2</sup>)\n",
    "    * the smaller the AIC, the better the model fit\n",
    "    * AIC does not have a range, unlike R<sup>2</sup>\n",
    "    * AIC formula (note: # parameters include intercept):\n",
    "\n",
    "\\begin{equation*}\n",
    "AIC = -2 LL(\\hat \\beta) + 2(\\#\\ parameters)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the log odds\n",
    "\\begin{equation*}\n",
    "Log odds = log(\\frac{P(Field=1)}{P(Field=0)}) = 3.96 - 0.119Temp + 0.00869Pres\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict(glm_model, newdata=orings) # this is logodds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: \n",
    "\\begin{equation*}\n",
    "Odds = \\frac{P(Field=1)}{P(Field=0)} = e^{3.96 - 0.119Temp + 0.00869Pres}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the probability\n",
    "\n",
    "\\begin{equation*}\n",
    "P(Field=1) = \\frac{e^{3.96 - 0.119Temp + 0.00869Pres}}{1+e^{3.96 - 0.119Temp + 0.00869Pres}}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glm_predict<-predict(glm_model, newdata=orings,type=\"response\") # predict probabilities and store in variable\n",
    "glm_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining the confusion matrix with a threshold of 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table(glm_predict[1:138]>0.1, orings$Field[1:138])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True positive: 6, True negative: 110, False positive: 18, False negative 4\n",
    "\n",
    "\\begin{equation*}\n",
    "Accuracy = \\frac{110+6}{110+6+18+4} = 0.84\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We always want to compare our model against the baseline model, which is a model that predicts using the majority label across all test observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table(orings$Field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the majority of output is 0, the baseline model would predict 0 for all observation. In this case, we find that the baseline model performs better than the logistic regression model in terms of accuracy. However, in this domain of space travel, we are concerned about the false negative (i.e. predicting that there is no problem, when in fact there is a problem with the orings). Hence, we need to lower the threshold to reduce the false negatives.\n",
    "\n",
    "\\begin{equation*}\n",
    "Accuracy = \\frac{128}{128+10} = 0.92\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(ROCR)\n",
    "ROCRpred <- prediction(glm_predict[1:138], orings$Field[1:138]) # prediction(predicted_values, actual_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ROCRperf <- performance(ROCRpred, measure='tpr', x.measure='fpr')\n",
    "plot(ROCRperf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining the AUC value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "performance(ROCRpred, measure='auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Subset Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a different dataset for subset selection: Hitters.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hitters<-read.csv(\"Dataset/Hitters.csv\")\n",
    "hitters<-na.omit(hitters) # to remove na values\n",
    "hitters<-hitters[,2:21] # to remove first column of names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str(hitters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary(hitters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(leaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Using regression, we can select the best model at each size of subset (i.e. a subset with 1/2/3... features)\n",
    "\n",
    "Parameters of regsubsets:\n",
    "* **nvmax**: max size of feature subsets to examine (default=8)\n",
    "* **method**: search method (default=exhaustive search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hitters<-hitters[,2:21] # to remove first column of names\n",
    "regsubset_model1<-regsubsets(Salary~., data=hitters)\n",
    "regsubset_model2<-regsubsets(Salary~., data=hitters, nvmax=19)\n",
    "regsubset_model3<-regsubsets(Salary~., data=hitters, nvmax=19, method='forward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary(regsubset_model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary(regsubset_model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining the i) R<sup>2</sup>, ii) residual sum of squared and iii) adjusted R<sup>2</sup> value for various subset sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary(regsubset_model2)$rsq\n",
    "summary(regsubset_model2)$rss\n",
    "summary(regsubset_model2)$adjr2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the adjusted R<sup>2</sup>. You can do the same with the other 2 measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot(summary(regsubset_model2)$adjr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the subset of features with the highest adjusted R<sup>2</sup> and to obtain the list of features and its beta coefficients of a particular subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "which.max(summary(regsubset_model2)$adjr2)\n",
    "coef(regsubset_model2, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Lasso \n",
    "Motivation: Lasso is a regression method that penalizes the absolute size of beta coefficients and may force some of coefficient to zero, which removes the feature from the model. This allows for automatic feature selection during the training of model, as opposed to subset selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(glmnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "\n",
    "To run glmnet(), we need to pass i) the input matrix and ii) the vector output. This is abit different from the typical y~x format that we are used to. Furthermore, glmnet works only with quantitative variables, hence it will expand 'factor' variables to dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x<-model.matrix(Salary~., data=hitters)\n",
    "y<-hitters$Salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set.seed(1) # always set seed the line before\n",
    "train<-sample(1:nrow(x),nrow(x)/2) # if unclear about sample(), refer to above\n",
    "test<--train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "For each lambda value, glmnet will find the LASSO model with the least error using the following objective function\n",
    "\n",
    "\\begin{equation*}\n",
    "\\min_{\\beta_{0},\\beta_{1},...,\\beta_{p}} \\sum_{i=1}^n (y_{i}-\\beta_{0}-\\beta_{1}x_{1}-...-\\beta_{p}x_{p})^2 + \\lambda\\sum_{j=1}^p \\beta_{j}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate a range of lambda values for LASSO model\n",
    "grid<-10^seq(10,-2,length=10)\n",
    "lasso_model<-glmnet(x[train,],y[train],lambda=grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of model\n",
    "\n",
    "Obtaining the i) overview of the model, ii) number of non-zero coefficients for each lambda value, iii) coefficient of beta for each lambda value in a matrix, iv) coefficient of beta for a SINGLE lambda value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:  glmnet(x = x[train, ], y = y[train], lambda = grid) \n",
       "\n",
       "      Df   %Dev    Lambda\n",
       " [1,]  0 0.0000 1.000e+10\n",
       " [2,]  0 0.0000 4.642e+08\n",
       " [3,]  0 0.0000 2.154e+07\n",
       " [4,]  0 0.0000 1.000e+06\n",
       " [5,]  0 0.0000 4.642e+04\n",
       " [6,]  0 0.0000 2.154e+03\n",
       " [7,]  4 0.2940 1.000e+02\n",
       " [8,] 15 0.4666 4.642e+00\n",
       " [9,] 16 0.5117 2.154e-01\n",
       "[10,] 19 0.5118 1.000e-02"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0</li>\n",
       "\t<li>0</li>\n",
       "\t<li>0</li>\n",
       "\t<li>0</li>\n",
       "\t<li>0</li>\n",
       "\t<li>0</li>\n",
       "\t<li>4</li>\n",
       "\t<li>15</li>\n",
       "\t<li>16</li>\n",
       "\t<li>19</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 4\n",
       "\\item 15\n",
       "\\item 16\n",
       "\\item 19\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0\n",
       "2. 0\n",
       "3. 0\n",
       "4. 0\n",
       "5. 0\n",
       "6. 0\n",
       "7. 4\n",
       "8. 15\n",
       "9. 16\n",
       "10. 19\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1]  0  0  0  0  0  0  4 15 16 19"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   [[ suppressing 10 column names ‘s0’, ‘s1’, ‘s2’ ... ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20 x 10 sparse Matrix of class \"dgCMatrix\"\n",
       "                                                                           \n",
       "(Intercept) . . . . . . .             .             .           .          \n",
       "AtBat       . . . . . . .            -0.97382543   -2.4346012  -2.509395393\n",
       "Hits        . . . . . . .             2.01213477    7.8640149   8.138007677\n",
       "HmRun       . . . . . . .             3.25581418   10.9961775  11.263846136\n",
       "Runs        . . . . . . .            -0.18278495   -8.5053021  -8.861150026\n",
       "RBI         . . . . . . 0.59971527    1.56917786    2.5060090   2.595295156\n",
       "Walks       . . . . . . 3.75683540    5.55655142    8.9690997   9.111538010\n",
       "Years       . . . . . . .           -20.06682427  -22.8754402 -23.329644508\n",
       "CAtBat      . . . . . . .             .            -0.1896439  -0.192317509\n",
       "CHits       . . . . . . .             .             .          -0.001649773\n",
       "CHmRun      . . . . . . .            -0.09581282   -1.1303941  -1.123748167\n",
       "CRuns       . . . . . . 0.25235106    1.00322441    3.1291210   3.206233290\n",
       "CRBI        . . . . . . .             .             .          -0.029500099\n",
       "CWalks      . . . . . . .            -0.27511140   -1.0013378  -1.030514624\n",
       "LeagueN     . . . . . . .            47.02476728   59.2265768  60.113882849\n",
       "DivisionW   . . . . . . .          -133.53553976 -100.1699127 -98.707169860\n",
       "PutOuts     . . . . . . 0.08917097    0.34583193    0.3393477   0.340091757\n",
       "Assists     . . . . . . .             0.13333462    0.3339655   0.342405440\n",
       "Errors      . . . . . . .             .            -0.6353566  -0.710285856\n",
       "NewLeagueN  . . . . . . .             4.37076475    .          -0.660710363"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "21 x 1 sparse Matrix of class \"dgCMatrix\"\n",
       "                       1\n",
       "(Intercept) 255.93476937\n",
       "(Intercept)   .         \n",
       "AtBat         .         \n",
       "Hits          .         \n",
       "HmRun         .         \n",
       "Runs          .         \n",
       "RBI           0.59971527\n",
       "Walks         3.75683540\n",
       "Years         .         \n",
       "CAtBat        .         \n",
       "CHits         .         \n",
       "CHmRun        .         \n",
       "CRuns         0.25235106\n",
       "CRBI          .         \n",
       "CWalks        .         \n",
       "LeagueN       .         \n",
       "DivisionW     .         \n",
       "PutOuts       0.08917097\n",
       "Assists       .         \n",
       "Errors        .         \n",
       "NewLeagueN    .         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lasso_model # check names(lasso_model) if unsure\n",
    "lasso_model$df\n",
    "lasso_model$beta #or coef(lasso_model) to see the intercept beta0\n",
    "coef(lasso_model, s = 1.000e+02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the beta coefficient values for each lambda. The values of coefficient tends to zero as lambda increases. As illustrated in the lasso equation, as lambda increases, the term $\\lambda \\sum_{j=1}^p \\beta_{j}$ becomes more important. Since this is a minimization problem, beta naturally will tend to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot(lasso_model, xvar = 'lambda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict values using LASSO model\n",
    "\n",
    "Recall the grid values used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Default: all lambda values used in the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict(lasso_model, newx=x[test,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using a specific lambda value of the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict(lasso_model, newx=x[test,], s=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using a specific lambda value within the range of the grid but not a value of the grid (linear interpolation). If you used a lambda value outside of the range of the grid, it will still be linearly extrapolataed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict(lasso_model, newx=x[test,], s=1.25e+02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using a specific value of the grid without linear interpolation. You need to refit the model with the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict(lasso_model, newx=x[test,], s=1.25e+02, exact=T, x=x[train,], y=y[train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the mean squared error of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted <- predict(lasso_model, newx=x[test,], s=100)\n",
    "mean((predicted-y[test])^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cross validation for Lasso\n",
    "\n",
    "Motivation: while we have been able to generate a list of fitted model with a range of lambda values, we are still unsure which lambda value to choose. Granted, we can derive the mean squared error for our prediction, but thats only for one instance of the test set. We use a more robust method to help us decide: cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performs k-fold cross validation for glmnet, where k=10 by default. An illustration of k-fold with k=5. Note that the glmnet will run once to choose its own lambda sequence, hence it will run (k+1) times\n",
    "\n",
    "<img src=\"kfold.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "cvlasso_model<-cv.glmnet(x[train,],y[train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of model\n",
    "\n",
    "Obtaining the i) value of lambda that gives the lowest mean cross-validated error, ii) lambda values used, iii) mean cross-validated error for each lambda value, iv) number of non-zero coefficients for each lambda value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvlasso_model$lambda.min\n",
    "cvlasso_model$lambda\n",
    "cvlasso_model$cvm\n",
    "cvlasso_model$nzero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the optimal lambda value, we can predict values using original LASSO model in 6. Lasso\n",
    "* Using a specific lambda value of the grid without linear interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict(lasso_model, newx=x[test,], s=16.7801585216616, exact=T, x=x[train,], y=y[train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the beta coefficients for a selected lambda value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coef(lasso_model, s = 16.7801585216616)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
